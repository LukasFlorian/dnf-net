<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>doku</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<h1 id="dokumentation-programmentwurf-1">Dokumentation Programmentwurf
1</h1>
<p>Yannik Angeli, Nils Kubousek, Lukas Richter, Diego Rubio Carrera</p>
<p><strong>Inhaltsverzeichnis:</strong></p>
<ul>
<li><a href="#dokumentation-programmentwurf-1">Dokumentation
Programmentwurf 1</a>
<ul>
<li><a href="#projektübersicht">Projektübersicht</a></li>
<li><a href="#architektur">Architektur</a></li>
<li><a href="#codestruktur">Codestruktur</a>
<ul>
<li><a href="#netpy"><code>net.py</code></a></li>
<li><a href="#trainpy"><code>train.py</code></a></li>
<li><a href="#helperspy"><code>helpers.py</code></a></li>
</ul></li>
<li><a href="#netzwerkbetrieb">Netzwerkbetrieb</a>
<ul>
<li><a href="#initialisierung">Initialisierung</a></li>
<li><a href="#inferenz">Inferenz</a></li>
<li><a href="#training">Training</a></li>
</ul></li>
<li><a href="#verwendung">Verwendung</a></li>
<li><a href="#beispiel">Beispiel</a></li>
</ul></li>
</ul>
<h2 id="projektübersicht">Projektübersicht</h2>
<p>Dieses Projekt implementiert ein zweischichtiges, vorwärtsgetriebenes
neuronales Netzwerk, das disjunktive Normalform (DNF)-Formeln der
Aussagenlogik realisieren kann. Die Implementierung umfasst eine
Netzwerkarchitektur, die logische Operationen auf Gewichte und
Schwellenwerte des neuronalen Netzes abbildet, sowie einen
Backpropagation-Algorithmus für das Training.</p>
<h2 id="architektur">Architektur</h2>
<p>Das neuronale Netzwerk besteht aus drei Schichten: -
<strong>Eingabeschicht</strong>: Nimmt binäre Eingaben entgegen, die
Wahrheitswerte repräsentieren (-1 für falsch, 1 für wahr) -
<strong>Zwischenschicht</strong>: Enthält Neuronen, die Monome
(Konjunktionen von Literalen) darstellen -
<strong>Ausgabeschicht</strong>: Ein einzelnes Neuron, das die gesamte
DNF-Formel (Disjunktion von Monomen) repräsentiert</p>
<h2 id="codestruktur">Codestruktur</h2>
<p>Das Projekt ist in mehrere Module organisiert:</p>
<h3 id="net.py"><code>net.py</code></h3>
<p>Enthält die zentrale <code>DNFNet</code>-Klasse, die das neuronale
Netzwerk implementiert. Zu den Hauptfunktionen gehören: 1.
<code>__init__(self, input_length: int = 10, num_monomers: int = 5, learning_rate: float = 0.1)</code>:
Initialisierung mit konfigurierbarer Eingabegröße, Anzahl der Monome und
Lernrate</p>
<ol start="2" type="1">
<li><p><code>inference(self, inputs: list[int]) -&gt; tuple[int, list[int]]</code>:
Vorwärtspropagation zur Berechnung der Netzwerkausgabe</p></li>
<li><p><code>backpropagation(self, inputs: list[int], target: int, result: int, monomer_activations: list[int]) -&gt; None</code>:
Backpropagation-Algorithmus zur Aktualisierung von Gewichten und
Schwellenwerten anhand des Eingabemusters, der Zielausgabe und der
tatsächlichen Ergebnisse des Netzwerks.</p></li>
<li><p><code>train(self, inputs: list[int], target: int) -&gt; tuple[int, list[int]]</code>:
Trainiert das Netzwerk mit einem gegebenen Eingabemuster und der
entsprechenden Zielausgabe, kombiniert also die Methoden
<code>inference</code> und <code>backpropagation</code></p></li>
<li><p><code>activation(self, num: float | int)</code>: Implementierung
der Signumfunktion als Aktivierungsfunktion</p></li>
<li><p><code>__str__(self) -&gt; str</code>: Dient der Formatierung der
Netzwerkkonfiguration für die Ausgabe</p></li>
<li><p><code>__call__(self, inputs: list[int], target: int = 0, train: bool = False) -&gt; tuple[int, list[int]]</code>:
Ermöglicht die Aufruf des Netzwerks wie eine Funktion, um Vorhersagen zu
treffen. Erlaubt dabei neben auch die Angabe eines Booleans
<code>train</code>, der angibt, ob das Netzwerk im Trainings- oder
Inferenz-Modus arbeiten soll</p></li>
<li><p><code>__eq__(self, value: object) -&gt; bool</code>: Dient der
Vergleichbarkeit von Netzwerken anhand deren Gewichten und
Schwellwerten, gibt False zurück, wenn <code>value</code> kein
<code>DNFNet</code> ist</p></li>
<li><p><code>shape(self) -&gt; tuple[int, int]</code>: Property, die die
Netzwerksdimensionen (Eingabelänge und Anzahl der Monome) als Tupel
zurückgibt</p></li>
</ol>
<h3 id="train.py"><code>train.py</code></h3>
<p>Implementiert die überwachte Trainingsfunktionalität durch die
<code>supervised_train</code>-Funktion, die: - Ein korrektes Netzwerk
(Referenz) - und ein Trainingsnetzwerk entgegennimmt - sowie die
Spezifizierung eines Epochenlimits erlaubt - Das Netzwerk iterativ mit
allen möglichen Eingabekombinationen trainiert, wobei die korrekte
Ausgabe durch das übergebene <code>correct_net</code> berechnet wird -
Die Anzahl der falschen Netzwerkvorhersagen pro Epoche verfolgt - Fehler
auf Monomerebene für detaillierte Analysen überwacht - Dabei ist zu
beachten, dass die Reihenfolge der Monome im Trainingsnetzwerk nicht
zwingend mit der des Referenznetzwerks übereinstimmen muss, die hier
erfassten Werte also begrenzte Aussagekraft haben - Konvergenzkriterien
und Maximallimits für Epochen implementiert - erfolgt eine gesamte
Epoche ohne Aktualisierung der Gewichte, wird die Konvergenz als
erreicht angesehen und das Netzwerk nicht weiter trainiert. Anderenfalls
wird es bis zum Erreichen des Epochenlimits trainiert.</p>
<h3 id="helpers.py"><code>helpers.py</code></h3>
<p>Bietet Hilfsfunktionen: 1.
<code>random_adjustment(factor: float = 1) -&gt; float</code>: Gibt
einen zufälligen Wert zwischen -1 und 1 oder -<code>factor</code> und
<code>factor</code> zurück</p>
<ol start="2" type="1">
<li><p><code>plot_network_results(network_misses: list[int|float]) -&gt; None</code>:
Erstellt ein Diagramm der Netzwerkfehler pro Epoche</p></li>
<li><p><code>plot_monomer_results(monomer_misses_per_epoch: list[list[int|float]]) -&gt; None</code>:
Erstellt ein Diagramm der Monomerfehler pro Epoche - wie in
<code>supervised_train</code> erwähnt, mit begrenzter
Aussagekraft</p></li>
<li><p><code>sma(series: list[int], window: int) -&gt; list[float]</code>:
Berechnet den gleitenden Durchschnitt (SMA) über eine bestimmte
Fenstergröße in einer Zeitreihe</p></li>
<li><p><code>plot_combined_sma(incorrect_per_epoch: list[int], monomer_misses_per_epoch: list[list[int]], window: int) -&gt; None</code>:
Erstellt ein Diagramm des gleitenden Durchschnitts der Netzwerk- und
Monomerfehler pro Epoche</p></li>
<li><p><code>visualize_results(network_misses: list[int], monomer_misses_per_epoch: list[list[int]], window: int = 100) -&gt; None</code>:
Visualisiert die Ergebnisse des Trainings mit Hilfe der obigen drei
Funktionen</p></li>
<li><p><code>plot_several_networks(network_misses: list[list[int]], names: list[str], window: int = 1) -&gt; None</code>:
Erstellt ein Diagramm vom SMA der Netzwerkfehler pro Epoche für mehrere
Netzwerke oder für dasselbe Netzwerk mit verschiedenen
Lernraten</p></li>
</ol>
<h2 id="netzwerkbetrieb">Netzwerkbetrieb</h2>
<h3 id="initialisierung">Initialisierung</h3>
<p>Das Netzwerk wird grundsätzlich mit zufälligen Parametern
initialisiert. Spezifische Gewichte müssen manuell per Zugriff auf die
Netzwerkattribute gesetzt werden.</p>
<h3 id="inferenz">Inferenz</h3>
<p>Während der Vorwärtspropagation: 1. Eingangssignale werden an jedem
Monomerneuron gewichtet und summiert - Die Vorzeichenfunktion wird
angewendet 2. Monomerausgaben werden am Ausgabeneuron gewichtet und
kombiniert - Die Vorzeichenfunktion wird angewendet 3. Die endgültige
Ausgabe repräsentiert den Wahrheitswert der Formel, die durch das
Netzwerk dargestellt wird</p>
<p>Mathematisch ausgedrückt gilt also: - <span
class="math inline"><em>n</em></span> Aussagenvariablen <span
class="math inline"><em>x</em><sub>1</sub>, …, <em>x</em><sub><em>n</em></sub></span>
(Eingangsneuronen) - Werte <span class="math inline">−1</span> (falsch)
und <span class="math inline">1</span> (wahr) - <span
class="math inline"><em>m</em></span> Monome <span
class="math inline"><em>z</em><sub>1</sub>, …, <em>z</em><sub><em>m</em></sub></span>
(Neuronen in Zwischenschicht) - Ein Ausgabeneuron <span
class="math inline"><em>y</em></span> - Aktivierungsfunktion <span
class="math inline">$sgn(x) = \begin{cases} 1 &amp; x \geq 0 \\ -1 &amp;
x &lt; 0 \end{cases}$</span> - Propagation in Vektorform: - <span
class="math inline"><em>z⃗</em> = <em>s</em><em>g</em><em>n</em>(<em>w</em> ⋅ <em>x⃗</em> − <em>v⃗</em>)</span>
- <span
class="math inline"><em>y</em> = <em>s</em><em>g</em><em>n</em>(<em>W</em> ⋅ <em>z⃗</em> − <em>V</em>)</span>
- mit Gewichtsmatrizen: - <span
class="math inline"><em>w</em> ∈ ℝ<sup><em>m</em> × <em>n</em></sup></span>
- <span
class="math inline"><em>W</em> ∈ ℝ<sup>1 × <em>m</em></sup></span> - und
Schwellwerten: - <span
class="math inline"><em>v⃗</em> ∈ ℝ<sup><em>m</em></sup></span> - <span
class="math inline"><em>V</em> ∈ ℝ</span></p>
<h3 id="training">Training</h3>
<p>Der Backpropagation-Algorithmus aktualisiert die Gewichte
folgendermaßen: - Lernalgorithmus mit Zielmuster <span
class="math inline"><em>p</em></span> und Lernrate <span
class="math inline"><em>η</em></span>: - <span
class="math inline"><em>Δ</em><em>W</em><sub>1<em>j</em></sub> = <em>μ</em> ⋅ (<em>p</em> − <em>y</em>) ⋅ <em>z</em><sub><em>j</em></sub></span>
- <span
class="math inline"><em>Δ</em><em>w</em><sub><em>j</em><em>k</em></sub> = <em>μ</em> ⋅ <em>W</em><sub>1<em>j</em></sub> ⋅ (<em>p</em> − <em>y</em>) ⋅ <em>x</em><sub><em>k</em></sub></span>
- <span
class="math inline"><em>Δ</em><em>V</em> = −<em>μ</em> ⋅ (<em>p</em> − <em>y</em>)</span>
- <span
class="math inline"><em>Δ</em><em>v</em><sub><em>j</em></sub> = −<em>μ</em> ⋅ (<em>p</em> − <em>y</em>) ⋅ <em>W</em><sub>1<em>j</em></sub></span></p>
<h2 id="verwendung">Verwendung</h2>
<p>Das Netzwerk in <code>net.py</code> und die Module
<code>helpers.py</code> sowie <code>train.py</code> können verwendet
werden, um: 1. Eine DNF-Formel direkt mit berechneten Gewichten zu
implementieren 2. Eine DNF-Formel durch überwachtes Training zu lernen,
wobei jedoch bereits Kenntnis über die korrekten Parameter vorausgesetzt
wird, sodass das Referenzmodell erstellt werden kann 3. Die Lernleistung
mit verschiedenen Parametern zu vergleichen 4. Den Lernprozess und die
Netzwerkkonvergenz zu visualisieren</p>
<h2 id="beispiel">Beispiel</h2>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.net <span class="im">import</span> DNFNet</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.train <span class="im">import</span> supervised_train</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.helpers <span class="im">import</span> visualize_results</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Referenznetzwerk mit vorberechneten Gewichten erstellen</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>correct_net <span class="op">=</span> DNFNet(input_length<span class="op">=</span><span class="dv">10</span>, num_monomers<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter entsprechend der DNF-Formel setzen:</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>correct_model.monomer_weights <span class="op">=</span> [</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>correct_model.monomer_biases <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>correct_model.output_weights <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>correct_model.output_bias <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Zu trainierendes Netzwerk erstellen</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>train_net <span class="op">=</span> DNFNet(input_length<span class="op">=</span><span class="dv">10</span>, num_monomers<span class="op">=</span><span class="dv">5</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Netzwerk trainieren</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>incorrect_per_epoch, monomer_misses <span class="op">=</span> supervised_train(correct_net, train_net)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Ergebnisse visualisieren</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>visualize_results(incorrect_per_epoch, monomer_misses)</span></code></pre></div>
</body>
</html>
